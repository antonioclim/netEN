================================================================================
SEMINAR 11 – DISTRIBUTED APPLICATIONS WITH NGINX
Load Balancing, Reverse Proxy, Docker Compose
Outline for PowerPoint/reveal.js presentation
================================================================================

SLIDE 1: TITLE
- Seminar 11 – Distributed Applications with Nginx
- Load Balancing & Reverse Proxy
- Docker Compose Orchestration

SLIDE 2: AGENDA
- Concepts: Reverse Proxy and Load Balancing
- Demo 1: Nginx with Docker Compose
- Demo 2: Custom Python Load Balancer
- Demo 3: Mininet Topology
- Practical exercises

SLIDE 3: LEARNING OBJECTIVES
- Configure Nginx as reverse proxy
- Implement load balancing algorithms
- Compare industrial solutions vs prototypes
- Diagnose problems with tcpdump/curl

================================================================================
SECTION 1: THEORETICAL CONCEPTS (6 slides)
================================================================================

SLIDE 4: WHAT IS A REVERSE PROXY
[Diagram: Client → Reverse Proxy → Backend(s)]
- "Reverse" proxy: represents servers, not clients
- Functions: load balancing, caching, SSL termination
- Examples: Nginx, HAProxy, Envoy, Traefik

SLIDE 5: FORWARD VS REVERSE PROXY (DIAGRAM)
[Comparative diagram]
- Forward: Client → Proxy → Internet (hides client)
- Reverse: Internet → Proxy → Servers (hides servers)
- Different use cases

SLIDE 6: LOAD BALANCING – WHY?
- Horizontal scalability (more servers)
- Availability (if one fails, others take over)
- Performance (uniform distribution)
- Maintenance (rolling updates)

SLIDE 7: LOAD BALANCING ALGORITHMS
| Algorithm | Description | When to use |
|-----------|-------------|-------------|
| Round Robin | Cyclic rotation | Default, simple |
| Weighted RR | Rotation with weights | Heterogeneous servers |
| Least Conn | Least busy | Variable duration requests |
| IP Hash | Hash on client IP | Sticky sessions |
| Random | Random | Uniform distribution |

SLIDE 8: HEALTH CHECKS
- Passive: detect errors from responses (5xx, timeout)
- Active: periodic probes GET /health
- Parameters: interval, threshold, timeout
- Action: temporary removal from pool

SLIDE 9: STICKY SESSIONS (SESSION PERSISTENCE)
[Diagram: same client → same backend]
- Problem: state in per-server memory
- Solutions: cookie, IP hash, custom header
- Trade-off: sticky vs uniform distribution

================================================================================
SECTION 2: DEMO NGINX + DOCKER COMPOSE (8 slides)
================================================================================

SLIDE 10: NGINX DEMO ARCHITECTURE
[Diagram: Client → Nginx:8080 → web1:8000, web2:8000, web3:8000]
- 3 simple Python backends
- 1 Nginx as reverse proxy/LB
- Docker Compose for orchestration

SLIDE 11: PROJECT STRUCTURE
```
docker/nginx_compose/
├── docker-compose.yml
├── nginx.conf
├── web1/index.html
├── web2/index.html
└── web3/index.html
```

SLIDE 12: docker-compose.yml (CODE)
```yaml
services:
  web1:
    image: python:3.11-alpine
    command: ["python3", "-m", "http.server", "8000"]
    volumes: ["./web1:/app"]
  # ... web2, web3 similar
  nginx:
    image: nginx:latest
    ports: ["8080:80"]
    volumes: ["./nginx.conf:/etc/nginx/nginx.conf:ro"]
    depends_on: [web1, web2, web3]
```

SLIDE 13: nginx.conf – UPSTREAM (CODE)
```nginx
upstream backends {
    server web1:8000;
    server web2:8000;
    server web3:8000;
}
server {
    listen 80;
    location / {
        proxy_pass http://backends;
    }
}
```

SLIDE 14: RUNNING NGINX DEMO
```bash
cd docker/nginx_compose
docker compose up -d
# Test round-robin
for i in {1..9}; do curl -s http://localhost:8080/; done
# Expected: web1, web2, web3, web1, web2, web3...
```

SLIDE 15: nginx.conf VARIANTS
```nginx
# Least connections
upstream backends { least_conn; server web1:8000; ... }

# IP Hash (sticky)
upstream backends { ip_hash; server web1:8000; ... }

# Weighted
upstream backends { server web1:8000 weight=3; server web2:8000; }
```

SLIDE 16: OBSERVING TRAFFIC
```bash
# Nginx Logs
docker compose logs -f nginx

# tcpdump in container
docker exec -it nginx tcpdump -i any -n tcp port 8000 -c 20

# Verify health
curl -I http://localhost:8080/
```

SLIDE 17: NGINX EXERCISE
1. Modify nginx.conf for least_conn
2. Restart: docker compose restart nginx
3. Test with 20 concurrent requests
4. Observe distribution in logs

================================================================================
SECTION 3: DEMO CUSTOM PYTHON LOAD BALANCER (8 slides)
================================================================================

SLIDE 18: WHY A CUSTOM LB?
- Understanding internal mechanisms
- Maximum flexibility (custom algorithms)
- Educational: we see exactly what happens
- Comparison with industrial solutions

SLIDE 19: PYTHON LB ARCHITECTURE
[Diagram: Client → simple_lb.py:8080 → backend1:8001, backend2:8002, backend3:8003]
- Python socket server
- Backend selection according to algorithm
- Transparent request/response proxy

SLIDE 20: ex_11_02_loadbalancer.py – STRUCTURE
```python
class LoadBalancer:
    def __init__(self, backends, algorithm):
        self.backends = backends
        self.algorithm = algorithm
        self.index = 0  # for round-robin
        self.connections = {}  # for least_conn
    
    def select_backend(self, client_ip):
        if self.algorithm == "rr":
            return self._round_robin()
        elif self.algorithm == "least_conn":
            return self._least_connections()
        elif self.algorithm == "ip_hash":
            return self._ip_hash(client_ip)
```

SLIDE 21: ROUND-ROBIN ALGORITHM (CODE)
```python
def _round_robin(self):
    backend = self.backends[self.index]
    self.index = (self.index + 1) % len(self.backends)
    return backend
```
- Simple and efficient
- Perfect distribution in the long term
- Does not account for effective load

SLIDE 22: LEAST CONNECTIONS ALGORITHM (CODE)
```python
def _least_connections(self):
    return min(
        self.backends,
        key=lambda b: self.connections.get(b, 0)
    )
```
- Accounts for active connections
- Better for variable duration requests
- Tracking overhead

SLIDE 23: IP HASH ALGORITHM (CODE)
```python
def _ip_hash(self, client_ip):
    hash_value = hash(client_ip)
    index = hash_value % len(self.backends)
    return self.backends[index]
```
- Same client → same backend (sticky)
- Useful for sessions/local state
- Possible imbalance

SLIDE 24: RUNNING PYTHON LB DEMO
```bash
# Terminal 1-3: start backends
make backends-start
# Terminal 4: start LB
make lb-start
# Terminal 5: test
for i in {1..9}; do curl -s http://localhost:8080/; done
```

SLIDE 25: NGINX VS PYTHON LB COMPARISON
| Aspect | Nginx | Python Custom |
|--------|-------|---------------|
| Performance | ~50,000 rps | ~1,000 rps |
| Config | Declarative | Programmatic |
| Health checks | Built-in | Manual |
| Overhead | Minimal | Python runtime |
| Flexibility | Limited | Maximum |
| Production | ✓ | ✗ (dev/edu only) |

================================================================================
SECTION 4: DEMO MININET (5 slides)
================================================================================

SLIDE 26: MININET TOPOLOGY
[Diagram: h1 ↔ s1 ↔ {h2, h3, h4} + h5(lb)]
- h1: client
- h2, h3, h4: backends
- h5: load balancer
- s1: OpenFlow switch

SLIDE 27: topo_11_base.py – STRUCTURE
```python
from mininet.topo import Topo
from mininet.net import Mininet

class LBTopo(Topo):
    def build(self):
        s1 = self.addSwitch('s1')
        client = self.addHost('h1', ip='10.0.0.1')
        lb = self.addHost('h5', ip='10.0.0.5')
        for i in [2, 3, 4]:
            h = self.addHost(f'h{i}', ip=f'10.0.0.{i}')
            self.addLink(h, s1)
        self.addLink(client, s1)
        self.addLink(lb, s1)
```

SLIDE 28: RUNNING MININET DEMO
```bash
sudo python3 mininet/topologies/topo_11_base.py --test
# or interactive:
sudo python3 mininet/topologies/topo_11_base.py --cli
mininet> h2 python3 -m http.server 8000 &
mininet> h1 curl http://10.0.0.2:8000/
```

SLIDE 29: TRAFFIC CAPTURE IN MININET
```bash
mininet> h5 tcpdump -i h5-eth0 -n tcp port 8080 -c 10
# or with tshark for details:
mininet> h5 tshark -i h5-eth0 -f "tcp port 8080" -c 10
```

SLIDE 30: MININET EXERCISE
1. Start the extended topology (topo_11_extended.py)
2. Configure routing on h5 as load balancer
3. Test with curl from h1
4. Capture and analyse traffic

================================================================================
SECTION 5: EXERCISES AND CONSOLIDATION (5 slides)
================================================================================

SLIDE 31: EXERCISE 1 – NGINX WEIGHTED
- Configure weights: web1=5, web2=2, web3=1
- Test with 80 requests
- Verify distribution (62.5%, 25%, 12.5%)

SLIDE 32: EXERCISE 2 – HEALTH CHECKS
```python
# Add to loadbalancer.py:
def health_check(self, backend):
    try:
        sock = socket.create_connection(backend, timeout=2)
        sock.close()
        return True
    except:
        return False
```

SLIDE 33: EXERCISE 3 – CUSTOM ALGORITHM
- Implement "Random with Weights"
- Backends have configurable weights
- Random selection accounts for weights

SLIDE 34: CHALLENGE EXERCISE – LEAST RESPONSE TIME
- Measure response time per-backend
- Select backend with lowest average time
- Exponential decay for moving average

SLIDE 35: PROJECT CONTRIBUTION
- Deliverable artefact: Functional Docker Compose
- Requirements: Nginx + min 2 backends + health script
- Documentation: README with instructions
- Deadline: according to calendar

================================================================================
RECAP (2 slides)
================================================================================

SLIDE 36: RECAP
- Reverse proxy: intermediary for backend servers
- Load balancing: request distribution (RR, least_conn, ip_hash)
- Nginx: industrial solution, declarative configuration
- Python LB: educational, mechanism understanding
- Mininet: real topology simulation

SLIDE 37: RESOURCES AND QUESTIONS
- Nginx docs: nginx.org/en/docs/
- HAProxy docs: haproxy.org
- Lab kit: starterkit_week_11/
- Questions?

================================================================================
TOTAL: ~37 slides
ESTIMATED TIME: 90-100 minutes (complete seminar)
================================================================================
